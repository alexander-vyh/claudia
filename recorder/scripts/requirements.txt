# Core transcription
mlx-whisper>=0.4.3
numpy

# Speaker diarization + identification
pyannote.audio>=4.0.0,<5.0
speechbrain>=1.0.0,<2.0
torch>=2.0.0,<2.9
torchaudio>=2.0.0,<2.9

# Correction pipeline dependencies (used via video-transcription-analysis)
pyyaml>=6.0
scipy>=1.10.0
spacy>=3.7.0
requests>=2.31.0
pydantic>=2.0.0
